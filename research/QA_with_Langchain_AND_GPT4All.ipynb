{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Information"
      ],
      "metadata": {
        "id": "Sw-GD_GSNWoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq1tsbOqNaPk",
        "outputId": "f89b1ec1-3346-45d6-c0d0-48c2a72f1f2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  5 13:52:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install & Import Libraries"
      ],
      "metadata": {
        "id": "agzeLowL_2Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain gpt4all pypdf chromadb -Uqq"
      ],
      "metadata": {
        "id": "Qqi0ECRr5xrH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import langchain\n",
        "from langchain.llms.gpt4all import GPT4All\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, GPT4AllEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "1K9c3TaU5zxz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yaRrjquOq0b",
        "outputId": "636ef4d4-05ca-4573-adef-a7987bcd866e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "RUXeuAA3_lkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "r_65YE45ALg6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v97Bn4eX4FYA"
      },
      "outputs": [],
      "source": [
        "# Download the GPT4All Model\n",
        "# !wget https://gpt4all.io/models/gguf/mistral-7b-openorca.Q4_0.gguf -Uqq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "DH7GG2BEAOr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained Model's Path\n",
        "model_checkpoint = \"/content/mistral-7b-openorca.Q4_0.gguf\"\n",
        "\n",
        "model = GPT4All(\n",
        "    model = model_checkpoint\n",
        ")"
      ],
      "metadata": {
        "id": "TYdMo3TG566m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "# response = model(\"Once upon a time, \")\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "dWMhqGl76ion"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Docs"
      ],
      "metadata": {
        "id": "vRxehHQlC1Er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "uuaFjIhbHTxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cse.iitk.ac.in/users/sigml/lec/Slides/Ram.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QCQLBonBw3z",
        "outputId": "e7177481-4b68-4b2f-8e71-0e7e27e270fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-05 13:52:40--  https://www.cse.iitk.ac.in/users/sigml/lec/Slides/Ram.pdf\n",
            "Resolving www.cse.iitk.ac.in (www.cse.iitk.ac.in)... 202.3.77.10\n",
            "Connecting to www.cse.iitk.ac.in (www.cse.iitk.ac.in)|202.3.77.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1024219 (1000K) [application/pdf]\n",
            "Saving to: ‘Ram.pdf.1’\n",
            "\n",
            "Ram.pdf.1           100%[===================>]   1000K   751KB/s    in 1.3s    \n",
            "\n",
            "2023-12-05 13:52:43 (751 KB/s) - ‘Ram.pdf.1’ saved [1024219/1024219]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load"
      ],
      "metadata": {
        "id": "kOnEwuMWHVLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/Ram.pdf\"\n",
        "\n",
        "# Load the pdf\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "# Pdf data\n",
        "pdf_data: list | None = loader.load()\n",
        "\n",
        "print(f\"Total number of pages: {len(pdf_data)}\")\n",
        "print(type(pdf_data))\n",
        "print(pdf_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOlOI6lbDrMI",
        "outputId": "902fada9-df1b-4e97-8221-06f03b62fa16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of pages: 19\n",
            "<class 'list'>\n",
            "[Document(page_content='Introduction to Deep Learning\\nM S Ram\\nDept. of Computer Science & Engg .\\nIndian Institute of Technology Kanpur\\nReading of Chap. 1 from “Learning Deep Architectures for AI”; Yoshua Bengio ; FTML Vol. 2, No. 1 (2009) 1 –127\\n1 Date: 12 Nov, 2015', metadata={'source': '/content/Ram.pdf', 'page': 0}), Document(page_content='A Motivational Task: Percepts\\uf0e0Concepts\\n•Create algorithms \\n•that can understand scenes and describe \\nthem in natural language\\n•that can infer semantic concepts to allow \\nmachines to interact with humans using these \\nconcepts\\n•Requires creating a series of abstractions\\n•Image (Pixel Intensities) \\uf0e0Objects in Image \\uf0e0Object \\nInteractions \\uf0e0Scene Description\\n•Deep learning aims to automatically learn these \\nabstractions with little supervision\\nCourtesy: Yoshua Bengio , Learning Deep Architectures for AI\\n2', metadata={'source': '/content/Ram.pdf', 'page': 1}), Document(page_content='Deep Visual -Semantic Alignments for Generating \\nImage Descriptions (Karpathy , Fei-Fei; CVPR 2015)\\n\"boy is doing backflip\\non wakeboard.\" \\n“two young girls are \\nplaying with lego toy.”\\n\"man in black shirt is \\nplaying guitar.\"  \\n\"construction worker in \\norange safety vest is \\nworking on road.\" \\nhttp://cs.stanford.edu/people/karpathy/deepimagesent/\\n3', metadata={'source': '/content/Ram.pdf', 'page': 2}), Document(page_content='Challenge in Modelling Complex Behaviour\\n•Too many concepts to learn\\n•Too many object categories\\n•Too many ways of interaction between objects categories\\n•Behaviour is a highly varying function underlying factors\\n•f: L \\uf0e0V\\n•L: latent factors of variation\\n•low dimensional latent factor space\\n•V: visible behaviour\\n•high dimensional observable space\\n•f: highly non -linear function\\n4', metadata={'source': '/content/Ram.pdf', 'page': 3}), Document(page_content='Example: Learning the Configuration Space of a Robotic Arm\\n5', metadata={'source': '/content/Ram.pdf', 'page': 4}), Document(page_content='C-Space Discovery using Isomap\\n6', metadata={'source': '/content/Ram.pdf', 'page': 5}), Document(page_content='How do We Train Deep Architectures?\\n•Inspiration from mammal brain\\n•Multiple Layers of “neurons” ( Rumelhart et al 1986)\\n•Train each layer to compose the representations of the previous layer \\nto learn a higher level abstraction \\n•Ex: Pixels \\uf0e0Edges \\uf0e0Contours \\uf0e0Object parts \\uf0e0Object categories\\n•Local Features \\uf0e0Global Features\\n•Train the layers one -by-one (Hinton et al 2006)\\n•Greedy strategy\\n7', metadata={'source': '/content/Ram.pdf', 'page': 6}), Document(page_content='Multilayer Perceptron with Back -propagation \\nFirst deep learning model (Rumelhart , Hinton, Williams 1986)\\ninput vectorhidden \\nlayersoutputsBack -propagate \\nerror signal to \\nget derivatives \\nfor learningCompare outputs with \\ncorrect answer to get \\nerror signal\\nSource: Hinton’s 2009 tutorial on Deep Belief Networks 8', metadata={'source': '/content/Ram.pdf', 'page': 7}), Document(page_content='Drawbacks of Back -propagation based Deep Neural \\nNetworks\\n•They are discriminative models\\n•Get all the information from the labels\\n•And the labels don’t give so much of information\\n•Need a substantial amount of labeled data\\n•Gradient descent with random initialization leads to poor local \\nminima', metadata={'source': '/content/Ram.pdf', 'page': 8}), Document(page_content='Hand -written digit recognition\\n•Classification of MNIST hand -written digits \\n•10 digit classes\\n•Input image: 28x28 gray scale\\n•784 dimensional input\\n', metadata={'source': '/content/Ram.pdf', 'page': 9}), Document(page_content='A Deeper Look at the Problem\\n•One hidden layer with 500 neurons\\n=> 784 * 500 + 500 * 10 \\n≈ 0.4 million weights\\n•Fitting a model that best explains the training data is an \\noptimization problem in a 0.4 million dimensional space\\n•It’s almost impossible for Gradient descent with random \\ninitialization to arrive at the global optimum', metadata={'source': '/content/Ram.pdf', 'page': 10}), Document(page_content='A Solution –Deep Belief Networks\\n(Hinton et al. 2006)\\nPre-trained \\nN/W  Weights\\nFast unsupervised\\npre-trainingGood \\nSolutionSlow Fine -tuning\\n(Using Back -propagation)\\nVery slow Back -propagation\\n(Often gets stuck at poor local minima)Random \\nInitial position\\nVery high -dimensional parameter space', metadata={'source': '/content/Ram.pdf', 'page': 11}), Document(page_content='A Solution –Deep Belief Networks\\n(Hinton et al. 2006)\\n•Before applying back -propagation, pre -train the network as a \\nseries of generative models\\n•Use the weights of the pre -trained network as the initial point \\nfor the traditional back -propagation\\n•This leads to quicker convergence to a good solution\\n•Pre-training is fast; fine -tuning can be slow', metadata={'source': '/content/Ram.pdf', 'page': 12}), Document(page_content='Quick Check: MLP vs DBN on MNIST\\n•MLP (1 Hidden Layer)\\n•1 hour: 2.18%\\n•14 hours: 1.65%\\n•DBN\\n•1 hour: 1.65%\\n•14 hours: 1.10%\\n•21 hours: 0.97%\\nIntel QuadCore 2.83GHz, 4GB RAM\\nMLP: Python :: DBN: Matlab', metadata={'source': '/content/Ram.pdf', 'page': 13}), Document(page_content='Intermediate Representations in Brain\\n•Disentanglement of factors of variation \\nunderlying the data\\n•Distributed Representations\\n•Activation of each neuron is a function of \\nmultiple features of the previous layer\\n•Feature combinations of different neurons \\nare not necessarily mutually exclusive\\n•Sparse Representations\\n•Only 1 -4% neurons are active at a time\\n15Localized Representation\\nDistributed Representation', metadata={'source': '/content/Ram.pdf', 'page': 14}), Document(page_content='Local vs. Distributed in Input Space\\n•Local Methods\\n•Assume smoothness prior\\n•g(x) = f(g(x1), g(x2), …, g( xk))\\n•{x1, x2, …, xk} are neighbours of x\\n•Require a metric space\\n•A notion of distance or similarity in the input space\\n•Fail when the target function is highly varying\\n•Examples\\n•Nearest Neighbour methods\\n•Kernel methods with a Gaussian kernel\\n•Distributed Methods\\n•No assumption of smoothness \\uf0e8No need for a notion of similarity\\n•Ex: Neural networks\\n16', metadata={'source': '/content/Ram.pdf', 'page': 15}), Document(page_content='Multi -task Learning\\n17\\nSource: https://en.wikipedia.org/wiki/Multi -task_learning', metadata={'source': '/content/Ram.pdf', 'page': 16}), Document(page_content='Desiderata for Learning AI\\n•Ability to learn complex, highly -varying functions\\n•Ability to learn multiple levels of abstraction with little human input\\n•Ability to learn from a very large set of examples\\n•Training time linear in the number of examples\\n•Ability to learn from mostly unlabeled data\\n•Unsupervised and semi -supervised\\n•Multi -task learning\\n•Sharing of representations across tasks\\n•Fast predictions\\n18', metadata={'source': '/content/Ram.pdf', 'page': 17}), Document(page_content='References\\n\\uf097Primary\\n\\uf097Yoshua Bengio , Learning Deep Architectures for AI , Foundations and Trends in Machine \\nLearning Vol. 2, No. 1 (2009) 1 –127\\n\\uf097Hinton, G. E., Osindero , S. and Teh, Y . A fast learning algorithm for deep belief nets . Neural \\nComputation 18 (2006), pp 1527 -1554\\n\\uf097Rumelhart , David E., Geoffrey E. Hinton, and R. J. Williams. Learning Internal \\nRepresentations by Error Propagation .David E. Rumelhart , James L. McClelland, and the \\nPDP research group. (editors), Parallel distributed processing: Explorations in the \\nmicrostructure of cognition, Volume 1: Foundations. MIT Press, 1986.\\n\\uf097Secondary\\n\\uf097Hinton, G. E., Learning Multiple Layers of Representation , Trends in Cognitive Sciences, Vol. \\n11, (2007 ) pp 428 -434.\\n\\uf097Hinton G.E., Tutorial on Deep Belief Networks , Machine Learning Summer School, \\nCambridge, 2009\\n\\uf097Andrej Karpathy , Li Fei-Fei. Deep Visual -Semantic Alignments for Generating Image \\nDescriptions . CVPR 2015.', metadata={'source': '/content/Ram.pdf', 'page': 18})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pdf_data[8].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrZVeuOmGtTC",
        "outputId": "c3447eb8-8047-4c5b-e8e8-1c40784801b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drawbacks of Back -propagation based Deep Neural \n",
            "Networks\n",
            "•They are discriminative models\n",
            "•Get all the information from the labels\n",
            "•And the labels don’t give so much of information\n",
            "•Need a substantial amount of labeled data\n",
            "•Gradient descent with random initialization leads to poor local \n",
            "minima\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "lF_tqKfSHX30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1024,\n",
        "    chunk_overlap = 64\n",
        ")\n",
        "\n",
        "texts: list | None = text_splitter.split_documents(pdf_data)\n",
        "\n",
        "print(type(texts))\n",
        "print(f\"{len(texts)} {texts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZmeItYLG3qQ",
        "outputId": "64551037-83f1-4a44-bb3e-011ad1cbaa3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "19 [Document(page_content='Introduction to Deep Learning\\nM S Ram\\nDept. of Computer Science & Engg .\\nIndian Institute of Technology Kanpur\\nReading of Chap. 1 from “Learning Deep Architectures for AI”; Yoshua Bengio ; FTML Vol. 2, No. 1 (2009) 1 –127\\n1 Date: 12 Nov, 2015', metadata={'source': '/content/Ram.pdf', 'page': 0}), Document(page_content='A Motivational Task: Percepts\\uf0e0Concepts\\n•Create algorithms \\n•that can understand scenes and describe \\nthem in natural language\\n•that can infer semantic concepts to allow \\nmachines to interact with humans using these \\nconcepts\\n•Requires creating a series of abstractions\\n•Image (Pixel Intensities) \\uf0e0Objects in Image \\uf0e0Object \\nInteractions \\uf0e0Scene Description\\n•Deep learning aims to automatically learn these \\nabstractions with little supervision\\nCourtesy: Yoshua Bengio , Learning Deep Architectures for AI\\n2', metadata={'source': '/content/Ram.pdf', 'page': 1}), Document(page_content='Deep Visual -Semantic Alignments for Generating \\nImage Descriptions (Karpathy , Fei-Fei; CVPR 2015)\\n\"boy is doing backflip\\non wakeboard.\" \\n“two young girls are \\nplaying with lego toy.”\\n\"man in black shirt is \\nplaying guitar.\"  \\n\"construction worker in \\norange safety vest is \\nworking on road.\" \\nhttp://cs.stanford.edu/people/karpathy/deepimagesent/\\n3', metadata={'source': '/content/Ram.pdf', 'page': 2}), Document(page_content='Challenge in Modelling Complex Behaviour\\n•Too many concepts to learn\\n•Too many object categories\\n•Too many ways of interaction between objects categories\\n•Behaviour is a highly varying function underlying factors\\n•f: L \\uf0e0V\\n•L: latent factors of variation\\n•low dimensional latent factor space\\n•V: visible behaviour\\n•high dimensional observable space\\n•f: highly non -linear function\\n4', metadata={'source': '/content/Ram.pdf', 'page': 3}), Document(page_content='Example: Learning the Configuration Space of a Robotic Arm\\n5', metadata={'source': '/content/Ram.pdf', 'page': 4}), Document(page_content='C-Space Discovery using Isomap\\n6', metadata={'source': '/content/Ram.pdf', 'page': 5}), Document(page_content='How do We Train Deep Architectures?\\n•Inspiration from mammal brain\\n•Multiple Layers of “neurons” ( Rumelhart et al 1986)\\n•Train each layer to compose the representations of the previous layer \\nto learn a higher level abstraction \\n•Ex: Pixels \\uf0e0Edges \\uf0e0Contours \\uf0e0Object parts \\uf0e0Object categories\\n•Local Features \\uf0e0Global Features\\n•Train the layers one -by-one (Hinton et al 2006)\\n•Greedy strategy\\n7', metadata={'source': '/content/Ram.pdf', 'page': 6}), Document(page_content='Multilayer Perceptron with Back -propagation \\nFirst deep learning model (Rumelhart , Hinton, Williams 1986)\\ninput vectorhidden \\nlayersoutputsBack -propagate \\nerror signal to \\nget derivatives \\nfor learningCompare outputs with \\ncorrect answer to get \\nerror signal\\nSource: Hinton’s 2009 tutorial on Deep Belief Networks 8', metadata={'source': '/content/Ram.pdf', 'page': 7}), Document(page_content='Drawbacks of Back -propagation based Deep Neural \\nNetworks\\n•They are discriminative models\\n•Get all the information from the labels\\n•And the labels don’t give so much of information\\n•Need a substantial amount of labeled data\\n•Gradient descent with random initialization leads to poor local \\nminima', metadata={'source': '/content/Ram.pdf', 'page': 8}), Document(page_content='Hand -written digit recognition\\n•Classification of MNIST hand -written digits \\n•10 digit classes\\n•Input image: 28x28 gray scale\\n•784 dimensional input', metadata={'source': '/content/Ram.pdf', 'page': 9}), Document(page_content='A Deeper Look at the Problem\\n•One hidden layer with 500 neurons\\n=> 784 * 500 + 500 * 10 \\n≈ 0.4 million weights\\n•Fitting a model that best explains the training data is an \\noptimization problem in a 0.4 million dimensional space\\n•It’s almost impossible for Gradient descent with random \\ninitialization to arrive at the global optimum', metadata={'source': '/content/Ram.pdf', 'page': 10}), Document(page_content='A Solution –Deep Belief Networks\\n(Hinton et al. 2006)\\nPre-trained \\nN/W  Weights\\nFast unsupervised\\npre-trainingGood \\nSolutionSlow Fine -tuning\\n(Using Back -propagation)\\nVery slow Back -propagation\\n(Often gets stuck at poor local minima)Random \\nInitial position\\nVery high -dimensional parameter space', metadata={'source': '/content/Ram.pdf', 'page': 11}), Document(page_content='A Solution –Deep Belief Networks\\n(Hinton et al. 2006)\\n•Before applying back -propagation, pre -train the network as a \\nseries of generative models\\n•Use the weights of the pre -trained network as the initial point \\nfor the traditional back -propagation\\n•This leads to quicker convergence to a good solution\\n•Pre-training is fast; fine -tuning can be slow', metadata={'source': '/content/Ram.pdf', 'page': 12}), Document(page_content='Quick Check: MLP vs DBN on MNIST\\n•MLP (1 Hidden Layer)\\n•1 hour: 2.18%\\n•14 hours: 1.65%\\n•DBN\\n•1 hour: 1.65%\\n•14 hours: 1.10%\\n•21 hours: 0.97%\\nIntel QuadCore 2.83GHz, 4GB RAM\\nMLP: Python :: DBN: Matlab', metadata={'source': '/content/Ram.pdf', 'page': 13}), Document(page_content='Intermediate Representations in Brain\\n•Disentanglement of factors of variation \\nunderlying the data\\n•Distributed Representations\\n•Activation of each neuron is a function of \\nmultiple features of the previous layer\\n•Feature combinations of different neurons \\nare not necessarily mutually exclusive\\n•Sparse Representations\\n•Only 1 -4% neurons are active at a time\\n15Localized Representation\\nDistributed Representation', metadata={'source': '/content/Ram.pdf', 'page': 14}), Document(page_content='Local vs. Distributed in Input Space\\n•Local Methods\\n•Assume smoothness prior\\n•g(x) = f(g(x1), g(x2), …, g( xk))\\n•{x1, x2, …, xk} are neighbours of x\\n•Require a metric space\\n•A notion of distance or similarity in the input space\\n•Fail when the target function is highly varying\\n•Examples\\n•Nearest Neighbour methods\\n•Kernel methods with a Gaussian kernel\\n•Distributed Methods\\n•No assumption of smoothness \\uf0e8No need for a notion of similarity\\n•Ex: Neural networks\\n16', metadata={'source': '/content/Ram.pdf', 'page': 15}), Document(page_content='Multi -task Learning\\n17\\nSource: https://en.wikipedia.org/wiki/Multi -task_learning', metadata={'source': '/content/Ram.pdf', 'page': 16}), Document(page_content='Desiderata for Learning AI\\n•Ability to learn complex, highly -varying functions\\n•Ability to learn multiple levels of abstraction with little human input\\n•Ability to learn from a very large set of examples\\n•Training time linear in the number of examples\\n•Ability to learn from mostly unlabeled data\\n•Unsupervised and semi -supervised\\n•Multi -task learning\\n•Sharing of representations across tasks\\n•Fast predictions\\n18', metadata={'source': '/content/Ram.pdf', 'page': 17}), Document(page_content='References\\n\\uf097Primary\\n\\uf097Yoshua Bengio , Learning Deep Architectures for AI , Foundations and Trends in Machine \\nLearning Vol. 2, No. 1 (2009) 1 –127\\n\\uf097Hinton, G. E., Osindero , S. and Teh, Y . A fast learning algorithm for deep belief nets . Neural \\nComputation 18 (2006), pp 1527 -1554\\n\\uf097Rumelhart , David E., Geoffrey E. Hinton, and R. J. Williams. Learning Internal \\nRepresentations by Error Propagation .David E. Rumelhart , James L. McClelland, and the \\nPDP research group. (editors), Parallel distributed processing: Explorations in the \\nmicrostructure of cognition, Volume 1: Foundations. MIT Press, 1986.\\n\\uf097Secondary\\n\\uf097Hinton, G. E., Learning Multiple Layers of Representation , Trends in Cognitive Sciences, Vol. \\n11, (2007 ) pp 428 -434.\\n\\uf097Hinton G.E., Tutorial on Deep Belief Networks , Machine Learning Summer School, \\nCambridge, 2009\\n\\uf097Andrej Karpathy , Li Fei-Fei. Deep Visual -Semantic Alignments for Generating Image \\nDescriptions . CVPR 2015.', metadata={'source': '/content/Ram.pdf', 'page': 18})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[3].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhEXUQ-8HmSD",
        "outputId": "aa60f190-77d4-44ea-ea89-1fecc3d6629f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Challenge in Modelling Complex Behaviour\n",
            "•Too many concepts to learn\n",
            "•Too many object categories\n",
            "•Too many ways of interaction between objects categories\n",
            "•Behaviour is a highly varying function underlying factors\n",
            "•f: L V\n",
            "•L: latent factors of variation\n",
            "•low dimensional latent factor space\n",
            "•V: visible behaviour\n",
            "•high dimensional observable space\n",
            "•f: highly non -linear function\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "3gZj4MmcIhm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GPT4AllEmbeddings(\n",
        "    model = model_checkpoint\n",
        ")\n",
        "print(embeddings)\n",
        "\n",
        "db = Chroma.from_documents(\n",
        "    texts,\n",
        "    embeddings,\n",
        "    persist_directory = \"db\"\n",
        ")\n",
        "print(db)\n",
        "\n",
        "# Demo\n",
        "print(embeddings.embed_documents([\"Subrata\", \"Mondal\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67DsKkUPIQxt",
        "outputId": "ea602546-fc09-4b0c-eb22-644781a67730"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=<gpt4all.gpt4all.Embed4All object at 0x797e5353b430>\n",
            "<langchain.vectorstores.chroma.Chroma object at 0x797e5351c160>\n",
            "[[-0.09711340069770813, 0.000904667773284018, -0.024697553366422653, -0.04399970918893814, 0.01615772396326065, -0.07538696378469467, -0.006384008564054966, 0.05518573895096779, -0.04213697835803032, -0.030894434079527855, -0.005064909812062979, -0.0455617792904377, -0.008511842228472233, -0.02269393764436245, -0.015313736163079739, 0.049883000552654266, 0.04793348163366318, 0.01194586418569088, 0.013956594280898571, -0.12195905297994614, 0.04416993260383606, 0.0912923738360405, -0.012974007055163383, -0.015094476751983166, 0.007220440078526735, -0.015183888375759125, -0.019292157143354416, -0.026059553027153015, -0.013971583917737007, -0.00977165438234806, -0.012909025885164738, 0.020741993561387062, 0.05236663669347763, -0.062396060675382614, 0.042088862508535385, 0.028679868206381798, -0.0708686113357544, -0.059478510171175, 0.04030084237456322, 0.08358591794967651, -0.05377691239118576, -0.0250555332750082, 0.007106369826942682, 0.025749970227479935, -0.003746595699340105, -0.033870499581098557, -0.08791138976812363, -0.013561272993683815, 0.03642651438713074, 0.02292780578136444, 0.031666602939367294, -0.0637463629245758, -0.02982570417225361, 0.07399861514568329, 0.09595091640949249, -0.0007890444830991328, -0.10020063817501068, 0.01713702082633972, 0.0761619582772255, -0.01663784310221672, -0.0042981477454304695, 0.03898649290204048, -0.02843501605093479, -0.0936872661113739, 0.08922833949327469, 0.012782200239598751, -0.03182552382349968, -0.030304471030831337, -0.034760814160108566, 0.07061970233917236, 0.022446593269705772, 0.029833747074007988, -0.01971331052482128, 0.03538291156291962, -0.08581157773733139, -0.046174243092536926, -0.029680997133255005, -0.01917194575071335, 0.011471303179860115, -0.04183784872293472, 0.0023019539657980204, 0.09482817351818085, 0.024913014844059944, -0.04759038984775543, -0.0074011534452438354, 0.014387303963303566, 0.08112937957048416, -0.08132290840148926, -0.05083690583705902, -0.025128299370408058, 0.04974975436925888, -0.03881239891052246, 0.01536989863961935, -0.02807796746492386, -0.09582635760307312, -0.008259871043264866, -0.002984188264235854, 0.039189182221889496, 0.03150002658367157, 0.3063294589519501, -0.01007513515651226, 0.11931761354207993, -0.028719251975417137, 0.02633356861770153, -0.08316107094287872, -0.05404355004429817, 0.0638694241642952, 0.023823902010917664, -0.01122264564037323, 0.06267298758029938, -0.03801834210753441, -0.01409823540598154, -0.027390962466597557, -0.096723273396492, 0.03514937311410904, 0.0016819338779896498, 0.04988759383559227, 0.10045389831066132, -0.06104850023984909, 0.04825742170214653, 0.005361195188015699, 0.05401308834552765, 0.02379552647471428, -0.0006601837230846286, 0.07310914993286133, -0.06645069271326065, -0.026347333565354347, 1.759638636048161e-33, 0.06476595252752304, -0.04424622654914856, 0.0058422209694981575, 0.07583091408014297, 0.02837025746703148, -0.045550957322120667, -0.05012156441807747, -0.07068532705307007, -0.0349484458565712, 0.067454032599926, 0.0027506654150784016, -0.0020385473035275936, -0.1124015673995018, -0.08452556282281876, 0.027904225513339043, 0.007985983043909073, 0.006974696647375822, -0.047370508313179016, -0.06605502218008041, -0.003209176706150174, 0.06493866443634033, 0.020828330889344215, 0.07300344109535217, -0.04100097715854645, -0.062007855623960495, -0.041837356984615326, 0.009290803223848343, -0.028726277872920036, 0.03719190135598183, 0.02931986004114151, -0.053791653364896774, 0.09016306698322296, 0.0015072259120643139, -0.037112679332494736, -0.02800397016108036, -0.04975602775812149, 0.005261530168354511, -0.022099284455180168, -0.053592946380376816, 0.03509756177663803, -0.039764370769262314, 0.038312461227178574, -0.0267269816249609, -0.05801507085561752, 0.10118567943572998, -0.020829342305660248, 0.08250920474529266, 0.0793285146355629, 0.05608879402279854, 0.01586773432791233, -0.011304324492812157, 0.006501000840216875, -0.029139649122953415, -0.057934366166591644, -0.013820996508002281, -0.03209570422768593, 0.03645932301878929, 0.020978035405278206, 0.05025011673569679, 0.01945437863469124, 0.016899187117815018, -0.013702967204153538, 0.040537379682064056, -0.021909404546022415, -0.09107190370559692, 0.06490392982959747, -0.057267848402261734, -0.011392584070563316, 0.021476445719599724, -0.0863429456949234, -0.02655099332332611, -0.014028488658368587, -0.013588101603090763, 0.17177753150463104, -0.09299054741859436, -0.007611215114593506, 0.08695639669895172, -0.02785578928887844, -0.07137210667133331, -0.04435107111930847, -0.053079649806022644, -0.02794385328888893, 0.06569866836071014, 0.029535679146647453, 0.013831375166773796, 0.011296695098280907, -0.0034378618001937866, -0.060440193861722946, -0.00846980232745409, 0.06592100113630295, -0.03607191890478134, 0.003031218657270074, 0.015795601531863213, -0.05145525932312012, 0.12033271044492722, -7.442719164870605e-34, 0.022772276774048805, -0.020158836618065834, -0.13242056965827942, -0.050794463604688644, -0.04253553971648216, -0.00043788482435047626, 0.015634164214134216, 0.07771310955286026, 0.014352234080433846, 0.11992005258798599, -0.033373039215803146, 0.08244512230157852, -0.04686373472213745, -0.09479033946990967, -0.03669458627700806, 0.023597242310643196, 0.07601723074913025, 0.0039330436848104, -0.04788321629166603, -0.04394460842013359, -0.0075136166997253895, 0.024314071983098984, 0.026782914996147156, -0.04258039593696594, 0.06856966763734818, 0.11919824033975601, 0.01632452942430973, 0.09459993988275528, -0.05783476307988167, -0.05608115717768669, -0.005170945543795824, -0.016495494171977043, 0.027499176561832428, 0.03921123221516609, 0.0033396922517567873, -0.03352419659495354, 0.019093597307801247, 0.05664234980940819, 0.001916189561598003, -0.04878496751189232, -0.07924293726682663, 0.016190597787499428, -0.011130668222904205, -0.010385469533503056, 0.04374139383435249, -0.10204750299453735, 0.008243043906986713, -0.054022662341594696, 0.0469035767018795, -0.06125134229660034, -0.062466371804475784, -0.05745398625731468, 0.08159957081079483, -0.01193966157734394, -0.015529734082520008, 0.01474340446293354, -0.07460444420576096, 0.06802695989608765, 0.09195461124181747, 0.024530921131372452, 0.04026090353727341, 0.04163612425327301, -0.03330710530281067, 0.024277925491333008, 0.1014324501156807, 0.022001640871167183, 0.0023949695751070976, -0.00787479430437088, 0.04565044119954109, 0.01835641823709011, -0.02385319396853447, -0.044472139328718185, 0.013279429636895657, -0.08798632770776749, 0.01338614709675312, -0.02388857677578926, -0.05863552913069725, 0.03905916586518288, -0.022500673308968544, -0.029841801151633263, -0.05241018161177635, 0.0037417009007185698, -0.05746598169207573, 0.008188319392502308, -0.022339988499879837, 0.012468725442886353, 0.03269560635089874, 0.017390118911862373, -0.04131127893924713, -0.04388679936528206, -0.03864835575222969, 0.0028495858423411846, 0.09215132892131805, 0.02462403103709221, 0.0543651357293129, -1.3758612915637514e-08, 0.027020253241062164, -0.027979006990790367, -0.04720103740692139, 0.011037696152925491, 0.06910707801580429, 0.005801346618682146, -0.0694475769996643, 0.0023553280625492334, 0.02511007711291313, 0.04746115207672119, -0.06889162957668304, 0.029090281575918198, 0.021005278453230858, 0.004915047436952591, 0.015747878700494766, 0.04824607074260712, 0.08459626138210297, 0.0263141468167305, -0.04365868121385574, 0.0063246916979551315, 0.010421361774206161, 0.04226313531398773, 0.02013757824897766, 0.01796817034482956, -0.058742791414260864, -0.007993930019438267, 0.00953737460076809, 0.05597533658146858, -0.03370138257741928, 0.004666879773139954, -0.0022272698115557432, 0.08915845304727554, 0.036825016140937805, -0.0038030040450394154, 0.020994383841753006, 0.08014941960573196, 0.0322917141020298, 0.06207109987735748, -0.01651647686958313, -0.02779325470328331, 0.0021739299409091473, -0.054306626319885254, 0.059617847204208374, -0.011173306964337826, -0.06121862307190895, -0.030962947756052017, -0.042527783662080765, 0.02165473997592926, 0.040348753333091736, 0.010895272716879845, 0.053875137120485306, -0.035992737859487534, 0.014625631272792816, 0.021346399560570717, 0.029713885858654976, -0.024853739887475967, -0.005430723074823618, 0.02564939111471176, 0.002217985689640045, -0.009163201786577702, 0.02046831138432026, -0.0772470086812973, 0.019577041268348694, -0.004485746845602989], [0.006970157381147146, -0.030399058014154434, -0.017247328534722328, 0.010023834183812141, 0.09871497750282288, -0.10733189433813095, 0.026960739865899086, 0.004418640863150358, -0.0010449026012793183, 0.02110813371837139, -0.0181502103805542, -0.09546495974063873, -0.03440490737557411, 0.03767701983451843, 0.04730208218097687, 0.00819883681833744, -0.04619196429848671, 0.02237403765320778, 0.01880405656993389, 0.07542791217565536, -0.017734762281179428, 0.022900380194187164, 0.049980100244283676, -0.07105805724859238, 0.007892023772001266, 0.07879527658224106, -0.03585768863558769, -0.014439495280385017, 0.022459568455815315, -0.0979497954249382, 0.06435640901327133, 0.031377870589494705, 0.02462179772555828, -0.02619340270757675, 0.03919408097863197, 0.046272050589323044, -0.025986114516854286, 0.011631928384304047, 0.021116157993674278, -0.044953033328056335, -0.036655716598033905, 0.025519635528326035, -0.016567010432481766, -0.06292063742876053, -0.03521052002906799, 0.0013833841076120734, -0.01025940477848053, 0.06914107501506805, 0.056926924735307693, -0.018869630992412567, 0.017256610095500946, -0.05832556262612343, 0.00855243019759655, 0.05989827215671539, -0.004629442468285561, -0.040778376162052155, -0.0022825070191174746, -0.09333673864603043, 0.03278661146759987, 0.011195906437933445, -0.025925343856215477, -0.009666365571320057, -0.05260040611028671, -0.04140293225646019, 0.017973968759179115, -0.016218151897192, -0.022793516516685486, -0.02993522584438324, -0.005741212982684374, 0.009378130547702312, 0.027196502313017845, -0.013975296169519424, -0.035501740872859955, 0.04173538088798523, -0.0038346515502780676, -0.0033391728065907955, 0.043957311660051346, -0.0664314404129982, 0.062446270138025284, -0.04479634761810303, -0.0046698180958628654, -0.1055481806397438, -0.0005952652427367866, -0.005689371842890978, 0.07050575315952301, 0.008662400767207146, 0.006407934706658125, 0.09129443764686584, -0.039682209491729736, 0.018995344638824463, 0.0031573667656630278, 0.0955808013677597, 0.017542412504553795, -0.023445893079042435, -0.0618867501616478, 0.038722969591617584, 0.06719961762428284, 0.04251885414123535, 0.03466100990772247, 0.3154323399066925, -0.020429786294698715, -0.034896526485681534, -0.08472275733947754, 0.032608527690172195, 0.028345990926027298, -0.11126504838466644, 0.02415783703327179, 0.02729926072061062, -0.04625508561730385, -0.0032851246651262045, 0.02483288012444973, -0.042750392109155655, 0.03411697596311569, 0.026613403111696243, 0.03511258214712143, 0.0009064362966455519, 0.02406422421336174, 0.05057303607463837, -0.031263045966625214, -0.04375644028186798, -0.02216106653213501, 0.06756982207298279, 0.026307513937354088, -0.027111785486340523, 0.00946314912289381, -0.03535616770386696, -0.05651885271072388, 7.279119279417433e-34, 0.07157265394926071, 0.013888760469853878, -0.026541434228420258, -0.08284351229667664, 0.05887654796242714, 0.07557527720928192, -0.05726022273302078, 0.013428593054413795, 0.032573677599430084, -0.12496155500411987, -0.010996619239449501, 0.05191421881318092, -0.035668738186359406, 0.1050221174955368, 0.002932052593678236, -0.02915746346116066, 0.008411484770476818, 0.032761819660663605, 0.045420121401548386, -0.03261186555027962, 0.026689562946558, 0.03131077066063881, 0.013795895501971245, 0.09674043953418732, 0.030079154297709465, -0.014484100975096226, -0.050453849136829376, -0.0707223191857338, 0.09512858092784882, 0.03401823714375496, -0.09510205686092377, -0.01444108784198761, 0.07588035613298416, -0.05125761032104492, 0.028444062918424606, -0.03672681003808975, -0.057226456701755524, -0.02614213339984417, -0.08290223032236099, -0.05063518509268761, 0.04924437031149864, 0.00244501163251698, -0.019244737923145294, -0.05599281191825867, -0.08162267506122589, 0.08280804008245468, 0.027315758168697357, 0.012051798403263092, -0.07618734240531921, -0.004563438706099987, -0.027516089379787445, 0.04204300045967102, -0.04452541470527649, -0.015400293283164501, 0.00015134546265471727, -0.015025751665234566, 0.018928224220871925, -0.049129508435726166, 0.0030369688756763935, -0.04886332154273987, 0.029863731935620308, 0.18358419835567474, 0.06326805055141449, 0.07505086064338684, 0.03807549178600311, -0.01615007594227791, 0.021095696836709976, 0.0413399301469326, 0.01927787996828556, 0.05659833922982216, -0.07996520400047302, 0.09587942063808441, 0.0055364458821713924, 0.02592073380947113, 0.0430949367582798, 0.07998735457658768, -0.0247199647128582, 0.04756322130560875, -0.04218897223472595, -0.006971473805606365, -0.07633348554372787, 0.007745441514998674, 0.02750776708126068, -0.06365632265806198, 0.006750095169991255, 0.021517178043723106, 0.04264460876584053, -0.07956675440073013, 0.0009397751418873668, -0.04249551519751549, 0.02794487029314041, 0.018187548965215683, -0.025208730250597, -0.051804106682538986, -0.15333351492881775, -1.2336749845387558e-33, -0.03570253774523735, 0.0014313055435195565, 0.05520033836364746, 0.04141182079911232, 0.0006150284316390753, 0.011745194904506207, -0.03972212225198746, 0.024419939145445824, 0.08049053698778152, -0.04409751296043396, -0.010524866171181202, -0.02257048711180687, 0.04267621040344238, 0.0006360121187753975, 0.04182973504066467, -0.08098901063203812, 0.03605423867702484, -0.02072511613368988, -0.030629688873887062, -0.03257831931114197, -0.07395390421152115, 0.04739611968398094, 0.046688538044691086, -0.05839558690786362, 0.011218448169529438, 0.004958929494023323, -0.0014412031741812825, -0.05543426051735878, 0.0019877897575497627, -0.01653333380818367, 0.015917519107460976, 0.05763012170791626, 0.04651334881782532, -0.035412777215242386, 0.01742500439286232, 0.029640136286616325, 0.055482279509305954, -0.014384587295353413, 0.03844185918569565, 0.047136932611465454, 0.04996134340763092, 0.005873220507055521, -0.061446040868759155, -0.035690899938344955, -0.00815142598003149, -0.11452562361955643, -0.07671121507883072, 0.06192809343338013, -0.023246726021170616, -0.015310293063521385, -0.002665354171767831, -0.021442804485559464, 0.045156653970479965, -0.09225708991289139, 0.0033153146505355835, -0.06393971294164658, 0.06495598703622818, -0.02613387070596218, 0.058257635682821274, 0.041290853172540665, -0.04316584765911102, -0.09759391099214554, -0.059881146997213364, 0.01635022833943367, -0.05074094608426094, 0.035857390612363815, -0.03394989296793938, -0.02955411560833454, 0.040001578629016876, -0.012498138472437859, 0.01694994606077671, -0.018508968874812126, 0.018920274451375008, 0.10791868716478348, 0.05044129863381386, 0.051837675273418427, -0.008879493921995163, -0.0061767203733325005, 0.051804136484861374, -0.008530196733772755, -0.06150621920824051, -0.023050589486956596, -0.008547481149435043, -0.0017843678360804915, 0.055506784468889236, -0.061287157237529755, -0.03407343104481697, -0.10512394458055496, -0.02406003698706627, 0.005202421452850103, -0.018764832988381386, 0.039084143936634064, 0.06384987384080887, 0.09940236061811447, 0.040538132190704346, -1.3940431031755907e-08, -0.03750520944595337, -0.03798987343907356, 0.010806323029100895, 0.03442297503352165, 0.0612841472029686, 0.08336494117975235, 0.004606954753398895, -0.1274084746837616, 0.03830866515636444, -0.04299832135438919, 0.010258854366838932, 0.028165141120553017, 0.009749295189976692, -0.05937789008021355, -0.01882089301943779, 0.017393579706549644, 0.009661680087447166, -0.05182315409183502, -0.004789631348103285, -0.021189285442233086, -0.009308857843279839, -0.041148632764816284, -0.001443206099793315, -0.029861385002732277, -0.04741532355546951, -0.031060583889484406, -0.014513212256133556, -0.06529901176691055, -0.058786097913980484, -0.03834453225135803, 0.04197826609015465, 0.036604225635528564, 0.052448734641075134, 0.0038688713684678078, 0.01818891428411007, 0.004665582440793514, -0.051300037652254105, -0.04135671630501747, -0.07712119817733765, 0.10462521016597748, 0.09593651443719864, 0.03544417768716812, -0.09604572504758835, -0.023098040372133255, -0.057854343205690384, -0.08705397695302963, 0.020441098138689995, 0.008647842332720757, -0.017542222514748573, -0.06164545193314552, 0.05719153583049774, -0.016400886699557304, 0.05156486853957176, 0.06779839098453522, 0.07324201613664627, -0.06265892088413239, 0.02874009683728218, -0.0433431938290596, 0.0016113833989948034, 0.07397779077291489, 0.08147069066762924, 0.00561735313385725, 0.05902891233563423, 0.01984291709959507]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains"
      ],
      "metadata": {
        "id": "Ni0OUA7qMOH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm = model,\n",
        "    chain_type = \"stuff\",\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents = True,\n",
        "    verbose = False,\n",
        ")\n",
        "\n",
        "print(qa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtuctcylLKVs",
        "outputId": "4770c68f-03c9-4c10-da55-3cb0a73ab03a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=GPT4All(model='/content/mistral-7b-openorca.Q4_0.gguf', client=<gpt4all.gpt4all.GPT4All object at 0x797e64292c80>)), document_variable_name='context') return_source_documents=True retriever=VectorStoreRetriever(tags=['Chroma', 'GPT4AllEmbeddings'], vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x797e5351c160>, search_kwargs={'k': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask Questions"
      ],
      "metadata": {
        "id": "-llorwxQMpkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = qa(\"Can you give me a summary of the document. Use bullet points to mention the important points.\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOC4pGLJMh0w",
        "outputId": "95abbf61-8c60-44e4-90bf-f3222317612d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Can you give me a summary of the document. Use bullet points to mention the important points.', 'result': ' Multi-Task Learning is a machine learning technique that involves training an algorithm on multiple related tasks simultaneously, allowing it to learn from and transfer knowledge between these tasks. This approach can improve performance in various domains such as natural language processing, computer vision, and speech recognition.', 'source_documents': [Document(page_content='Multi -task Learning\\n17\\nSource: https://en.wikipedia.org/wiki/Multi -task_learning', metadata={'page': 16, 'source': '/content/Ram.pdf'}), Document(page_content='Multi -task Learning\\n17\\nSource: https://en.wikipedia.org/wiki/Multi -task_learning', metadata={'page': 16, 'source': '/content/Ram.pdf'}), Document(page_content='Multi -task Learning\\n17\\nSource: https://en.wikipedia.org/wiki/Multi -task_learning', metadata={'page': 16, 'source': '/content/Ram.pdf'})]}\n",
            "CPU times: user 15min 7s, sys: 986 ms, total: 15min 8s\n",
            "Wall time: 8min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joezW8y5M7tS",
        "outputId": "a25730b5-f5e0-4b42-f260-518b2c42d4ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Multi-Task Learning is a machine learning technique that involves training an algorithm on multiple related tasks simultaneously, allowing it to learn from and transfer knowledge between these tasks. This approach can improve performance in various domains such as natural language processing, computer vision, and speech recognition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZX4G1thSftI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}